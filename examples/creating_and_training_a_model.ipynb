{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow 2.3.1\n",
      "nfp 0.2.0+0.g72982c1.dirty\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import nfp\n",
    "\n",
    "print(f\"tensorflow {tf.__version__}\")\n",
    "print(f\"nfp {nfp.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>CAS</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Type</th>\n",
       "      <th>YSI</th>\n",
       "      <th>YSI_err</th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,2-diphenylbenzene</td>\n",
       "      <td>84-15-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>aromatic</td>\n",
       "      <td>1338.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>c1ccc(-c2ccccc2-c2ccccc2)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cyclopenta[def]phenanthrene</td>\n",
       "      <td>203-64-5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>aromatic</td>\n",
       "      <td>1312.8</td>\n",
       "      <td>73.5</td>\n",
       "      <td>c1cc2c3c(c1)ccc1cccc(c13)C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fluoranthene</td>\n",
       "      <td>206-44-0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>aromatic</td>\n",
       "      <td>1291.9</td>\n",
       "      <td>72.4</td>\n",
       "      <td>c1ccc2c(c1)-c1cccc3cccc-2c13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,3-diphenylbenzene</td>\n",
       "      <td>92-06-8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>aromatic</td>\n",
       "      <td>1286.6</td>\n",
       "      <td>72.3</td>\n",
       "      <td>c1ccc(-c2cccc(-c3ccccc3)c2)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pyrene</td>\n",
       "      <td>129-00-0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>aromatic</td>\n",
       "      <td>1250.1</td>\n",
       "      <td>70.1</td>\n",
       "      <td>c1cc2ccc3cccc4ccc(c1)c2c34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Species       CAS  Ref      Type     YSI  YSI_err  \\\n",
       "0          1,2-diphenylbenzene   84-15-1  2.0  aromatic  1338.9     50.0   \n",
       "1  cyclopenta[def]phenanthrene  203-64-5  2.0  aromatic  1312.8     73.5   \n",
       "2                 fluoranthene  206-44-0  2.0  aromatic  1291.9     72.4   \n",
       "3          1,3-diphenylbenzene   92-06-8  2.0  aromatic  1286.6     72.3   \n",
       "4                       pyrene  129-00-0  2.0  aromatic  1250.1     70.1   \n",
       "\n",
       "                           SMILES  \n",
       "0    c1ccc(-c2ccccc2-c2ccccc2)cc1  \n",
       "1     c1cc2c3c(c1)ccc1cccc(c13)C2  \n",
       "2    c1ccc2c(c1)-c1cccc3cccc-2c13  \n",
       "3  c1ccc(-c2cccc(-c3ccccc3)c2)cc1  \n",
       "4      c1cc2ccc3cccc4ccc(c1)c2c34  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the input data, here YSI (10.1016/j.combustflame.2017.12.005)\n",
    "ysi = pd.read_csv('../data/ysi.csv')\n",
    "ysi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341, 50, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "valid, test, train = np.split(ysi.SMILES.sample(frac=1., random_state=1), [50, 100])\n",
    "len(train), len(valid), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to featurize the input molecules\n",
    "\n",
    "def atom_featurizer(atom):\n",
    "    \"\"\" Return an string representing the atom type\n",
    "    \"\"\"\n",
    "\n",
    "    return str((\n",
    "        atom.GetSymbol(),\n",
    "        atom.GetIsAromatic(),\n",
    "        nfp.get_ring_size(atom, max_size=6),\n",
    "        atom.GetDegree(),\n",
    "        atom.GetTotalNumHs(includeNeighbors=True)\n",
    "    ))\n",
    "\n",
    "\n",
    "def bond_featurizer(bond, flipped=False):\n",
    "    \"\"\" Get a similar classification of the bond type.\n",
    "    Flipped indicates which 'direction' the bond edge is pointing. \"\"\"\n",
    "    \n",
    "    if not flipped:\n",
    "        atoms = \"{}-{}\".format(\n",
    "            *tuple((bond.GetBeginAtom().GetSymbol(),\n",
    "                    bond.GetEndAtom().GetSymbol())))\n",
    "    else:\n",
    "        atoms = \"{}-{}\".format(\n",
    "            *tuple((bond.GetEndAtom().GetSymbol(),\n",
    "                    bond.GetBeginAtom().GetSymbol())))\n",
    "    \n",
    "    btype = str(bond.GetBondType())\n",
    "    ring = 'R{}'.format(nfp.get_ring_size(bond, max_size=6)) if bond.IsInRing() else ''\n",
    "    \n",
    "    return \" \".join([atoms, btype, ring]).strip()\n",
    "\n",
    "\n",
    "preprocessor = nfp.SmilesPreprocessor(atom_features=atom_featurizer, bond_features=bond_featurizer,\n",
    "                                      explicit_hs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before pre-allocating\n",
      "{'unk': 1}\n",
      "\n",
      "after pre-allocating\n",
      "{'unk': 1, \"('C', False, 0, 1, 3)\": 2, \"('C', False, 0, 2, 2)\": 3, \"('C', False, 0, 3, 0)\": 4, \"('O', False, 0, 1, 0)\": 5, \"('O', False, 0, 2, 0)\": 6, \"('C', False, 0, 1, 2)\": 7, \"('C', False, 0, 2, 1)\": 8, \"('C', False, 0, 3, 1)\": 9, \"('C', False, 0, 4, 0)\": 10, \"('C', True, 'max', 2, 1)\": 11, \"('C', True, 'max', 3, 0)\": 12, \"('C', False, 'max', 2, 2)\": 13, \"('O', False, 0, 1, 1)\": 14, \"('C', False, 0, 1, 1)\": 15, \"('C', False, 0, 2, 0)\": 16, \"('C', False, 'max', 3, 1)\": 17, \"('N', False, 0, 1, 0)\": 18, \"('Br', False, 0, 1, 0)\": 19, \"('C', False, 'max', 2, 1)\": 20, \"('C', True, 5, 3, 0)\": 21, \"('C', False, 5, 2, 2)\": 22, \"('C', False, 5, 2, 1)\": 23, \"('C', False, 5, 3, 1)\": 24, \"('C', False, 5, 3, 0)\": 25, \"('C', False, 'max', 3, 0)\": 26, \"('O', False, 5, 2, 0)\": 27, \"('O', False, 'max', 2, 0)\": 28, \"('F', False, 0, 1, 0)\": 29, \"('C', True, 5, 2, 1)\": 30, \"('C', False, 'max', 4, 0)\": 31, \"('Cl', False, 0, 1, 0)\": 32, \"('C', False, 3, 3, 1)\": 33, \"('C', False, 3, 2, 2)\": 34, \"('O', False, 3, 2, 0)\": 35}\n"
     ]
    }
   ],
   "source": [
    "# Initially, the preprocessor has no data on atom types, so we have to loop over the \n",
    "# training set once to pre-allocate these mappings\n",
    "print(\"before pre-allocating\")\n",
    "print(preprocessor.atom_tokenizer._data)\n",
    "\n",
    "for smiles in train:\n",
    "    preprocessor(smiles, train=True)\n",
    "    \n",
    "print()\n",
    "print(\"after pre-allocating\")\n",
    "print(preprocessor.atom_tokenizer._data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3, 14])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main input types for a SMILES-based prediction\n",
    "smiles = 'CCO'\n",
    "\n",
    "# Atom types, as integer classes\n",
    "preprocessor(smiles, train=True)['atom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 5, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bond types, as integer classes\n",
    "preprocessor(smiles, train=True)['bond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 2],\n",
       "       [2, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A connectivity array, where row i indicates bond i connects atom j to atom k\n",
    "preprocessor(smiles, train=True)['connectivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the tf.data pipeline. There's a lot of specifying data types and\n",
    "# expected shapes for tensorflow to pre-allocate the necessary arrays. But \n",
    "# essentially, this is responsible for calling the input constructor, batching \n",
    "# together multiple molecules, and padding the resulting molecules so that all\n",
    "# molecules in the same batch have the same number of atoms (we pad with zeros,\n",
    "# hence why the atom and bond types above start with 1 as the unknown class)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ((preprocessor(row.SMILES, train=False), row.YSI)\n",
    "             for i, row in ysi[ysi.SMILES.isin(train)].iterrows()),\n",
    "    output_types=(preprocessor.output_types, tf.float32),\n",
    "    output_shapes=(preprocessor.output_shapes, []))\\\n",
    "    .cache().shuffle(buffer_size=200)\\\n",
    "    .padded_batch(batch_size=64, \n",
    "                  padded_shapes=(preprocessor.padded_shapes(), []),\n",
    "                  padding_values=(preprocessor.padding_values, 0.))\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ((preprocessor(row.SMILES, train=False), row.YSI)\n",
    "             for i, row in ysi[ysi.SMILES.isin(valid)].iterrows()),\n",
    "    output_types=(preprocessor.output_types, tf.float32),\n",
    "    output_shapes=(preprocessor.output_shapes, []))\\\n",
    "    .cache()\\\n",
    "    .padded_batch(batch_size=64, \n",
    "                  padded_shapes=(preprocessor.padded_shapes(), []),\n",
    "                  padding_values=(preprocessor.padding_values, 0.))\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the keras model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Input layers\n",
    "atom = layers.Input(shape=[None], dtype=tf.int64, name='atom')\n",
    "bond = layers.Input(shape=[None], dtype=tf.int64, name='bond')\n",
    "connectivity = layers.Input(shape=[None, 2], dtype=tf.int64, name='connectivity')\n",
    "\n",
    "num_features = 8  # Controls the size of the model\n",
    "\n",
    "# Convert from a single integer defining the atom state to a vector\n",
    "# of weights associated with that class\n",
    "atom_state = layers.Embedding(preprocessor.atom_classes, num_features,\n",
    "                              name='atom_embedding', mask_zero=True)(atom)\n",
    "\n",
    "# Ditto with the bond state\n",
    "bond_state = layers.Embedding(preprocessor.bond_classes, num_features,\n",
    "                              name='bond_embedding', mask_zero=True)(bond)\n",
    "\n",
    "# Here we use our first nfp layer. This is an attention layer that looks at\n",
    "# the atom and bond states and reduces them to a single, graph-level vector. \n",
    "# mum_heads * units has to be the same dimension as the atom / bond dimension\n",
    "global_state = nfp.GlobalUpdate(units=8, num_heads=1)([atom_state, bond_state, connectivity])\n",
    "\n",
    "for _ in range(3):  # Do the message passing\n",
    "    new_bond_state = nfp.EdgeUpdate()([atom_state, bond_state, connectivity, global_state])\n",
    "    bond_state = layers.Add()([bond_state, new_bond_state])\n",
    "    \n",
    "    new_atom_state = nfp.NodeUpdate()([atom_state, bond_state, connectivity, global_state])\n",
    "    atom_state = layers.Add()([atom_state, new_atom_state])\n",
    "    \n",
    "    new_global_state = nfp.GlobalUpdate(units=8, num_heads=1)(\n",
    "        [atom_state, bond_state, connectivity, global_state]) \n",
    "    global_state = layers.Add()([global_state, new_global_state])\n",
    "\n",
    "    \n",
    "# Since the final prediction is a single, molecule-level property (YSI), we \n",
    "# reduce the last global state to a single prediction.\n",
    "ysi_prediction = layers.Dense(1)(global_state)\n",
    "\n",
    "# Construct the tf.keras model\n",
    "model = tf.keras.Model([atom, bond, connectivity], [ysi_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pstjohn/miniconda3/envs/nfp/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['n_atom', 'n_bond', 'bond_indices'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 201ms/step - loss: 192.5282 - val_loss: 156.3338\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 191.6269 - val_loss: 154.2021\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 187.9288 - val_loss: 147.4886\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 178.0559 - val_loss: 131.6612\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 162.7336 - val_loss: 124.0303\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 162.0391 - val_loss: 125.7313\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 154.8945 - val_loss: 116.7943\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 149.2845 - val_loss: 113.8111\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 143.0998 - val_loss: 105.6354\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 127.5234 - val_loss: 93.4604\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 93.8345 - val_loss: 65.8470\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 73.4662 - val_loss: 62.8007\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 65.6246 - val_loss: 61.4815\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 63.4636 - val_loss: 61.4872\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 61.8959 - val_loss: 57.7244\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 58.3664 - val_loss: 52.4185\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 59.1145 - val_loss: 58.3494\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 56.9374 - val_loss: 52.7102\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 55.3144 - val_loss: 53.1646\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 53.2501 - val_loss: 48.5530\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 52.1931 - val_loss: 53.1881\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 53.9029 - val_loss: 46.2755\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 51.6329 - val_loss: 47.9711\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 51.6885 - val_loss: 46.3855\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 49.6647 - val_loss: 43.7484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe7427bfe10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mae', optimizer=tf.keras.optimizers.Adam(1E-3))\n",
    "\n",
    "# Fit the model. The first epoch is slower, since it needs to cache\n",
    "# the preprocessed molecule inputs\n",
    "model.fit(train_dataset, validation_data=valid_dataset, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we create a test dataset that doesn't assume we know the values for the YSI\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: (preprocessor(smiles, train=False)\n",
    "             for smiles in test),\n",
    "    output_types=preprocessor.output_types,\n",
    "    output_shapes=preprocessor.output_shapes)\\\n",
    "    .padded_batch(batch_size=64, \n",
    "                  padded_shapes=preprocessor.padded_shapes(),\n",
    "                  padding_values=preprocessor.padding_values)\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.5671657333374"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here are the predictions on the test set\n",
    "test_predictions = model.predict(test_dataset)\n",
    "test_db_values = ysi.set_index('SMILES').reindex(test).YSI.values\n",
    "\n",
    "np.abs(test_db_values - test_predictions.flatten()).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
