{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow 2.5.0\n",
      "nfp 0.3.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import nfp\n",
    "\n",
    "print(f\"tensorflow {tf.__version__}\")\n",
    "print(f\"nfp {nfp.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>CAS</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Type</th>\n",
       "      <th>YSI</th>\n",
       "      <th>YSI_err</th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,2-diphenylbenzene</td>\n",
       "      <td>84-15-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>aromatic</td>\n",
       "      <td>1338.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>c1ccc(-c2ccccc2-c2ccccc2)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cyclopenta[def]phenanthrene</td>\n",
       "      <td>203-64-5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>aromatic</td>\n",
       "      <td>1312.8</td>\n",
       "      <td>73.5</td>\n",
       "      <td>c1cc2c3c(c1)ccc1cccc(c13)C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fluoranthene</td>\n",
       "      <td>206-44-0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>aromatic</td>\n",
       "      <td>1291.9</td>\n",
       "      <td>72.4</td>\n",
       "      <td>c1ccc2c(c1)-c1cccc3cccc-2c13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,3-diphenylbenzene</td>\n",
       "      <td>92-06-8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>aromatic</td>\n",
       "      <td>1286.6</td>\n",
       "      <td>72.3</td>\n",
       "      <td>c1ccc(-c2cccc(-c3ccccc3)c2)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pyrene</td>\n",
       "      <td>129-00-0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>aromatic</td>\n",
       "      <td>1250.1</td>\n",
       "      <td>70.1</td>\n",
       "      <td>c1cc2ccc3cccc4ccc(c1)c2c34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Species       CAS  Ref      Type     YSI  YSI_err  \\\n",
       "0          1,2-diphenylbenzene   84-15-1  2.0  aromatic  1338.9     50.0   \n",
       "1  cyclopenta[def]phenanthrene  203-64-5  2.0  aromatic  1312.8     73.5   \n",
       "2                 fluoranthene  206-44-0  2.0  aromatic  1291.9     72.4   \n",
       "3          1,3-diphenylbenzene   92-06-8  2.0  aromatic  1286.6     72.3   \n",
       "4                       pyrene  129-00-0  2.0  aromatic  1250.1     70.1   \n",
       "\n",
       "                           SMILES  \n",
       "0    c1ccc(-c2ccccc2-c2ccccc2)cc1  \n",
       "1     c1cc2c3c(c1)ccc1cccc(c13)C2  \n",
       "2    c1ccc2c(c1)-c1cccc3cccc-2c13  \n",
       "3  c1ccc(-c2cccc(-c3ccccc3)c2)cc1  \n",
       "4      c1cc2ccc3cccc4ccc(c1)c2c34  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the input data, here YSI (10.1016/j.combustflame.2017.12.005)\n",
    "ysi = pd.read_csv('../data/ysi.csv')\n",
    "ysi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341, 50, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "valid, test, train = np.split(ysi.SMILES.sample(frac=1., random_state=1), [50, 100])\n",
    "len(train), len(valid), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to featurize the input molecules\n",
    "from nfp.preprocessing.mol_preprocessor import SmilesPreprocessor\n",
    "from nfp.preprocessing.features import get_ring_size\n",
    "\n",
    "\n",
    "def atom_featurizer(atom):\n",
    "    \"\"\" Return an string representing the atom type\n",
    "    \"\"\"\n",
    "\n",
    "    return str((\n",
    "        atom.GetSymbol(),\n",
    "        atom.GetIsAromatic(),\n",
    "        get_ring_size(atom, max_size=6),\n",
    "        atom.GetDegree(),\n",
    "        atom.GetTotalNumHs(includeNeighbors=True)\n",
    "    ))\n",
    "\n",
    "\n",
    "def bond_featurizer(bond, flipped=False):\n",
    "    \"\"\" Get a similar classification of the bond type.\n",
    "    Flipped indicates which 'direction' the bond edge is pointing. \"\"\"\n",
    "    \n",
    "    if not flipped:\n",
    "        atoms = \"{}-{}\".format(\n",
    "            *tuple((bond.GetBeginAtom().GetSymbol(),\n",
    "                    bond.GetEndAtom().GetSymbol())))\n",
    "    else:\n",
    "        atoms = \"{}-{}\".format(\n",
    "            *tuple((bond.GetEndAtom().GetSymbol(),\n",
    "                    bond.GetBeginAtom().GetSymbol())))\n",
    "    \n",
    "    btype = str(bond.GetBondType())\n",
    "    ring = 'R{}'.format(get_ring_size(bond, max_size=6)) if bond.IsInRing() else ''\n",
    "    \n",
    "    return \" \".join([atoms, btype, ring]).strip()\n",
    "\n",
    "\n",
    "preprocessor = SmilesPreprocessor(atom_features=atom_featurizer, bond_features=bond_featurizer,\n",
    "                                  explicit_hs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before pre-allocating\n",
      "{'unk': 1}\n",
      "\n",
      "after pre-allocating\n",
      "{'unk': 1, \"('C', False, 0, 1, 3)\": 2, \"('C', False, 0, 2, 2)\": 3, \"('C', False, 0, 3, 0)\": 4, \"('O', False, 0, 1, 0)\": 5, \"('O', False, 0, 2, 0)\": 6, \"('C', False, 0, 1, 2)\": 7, \"('C', False, 0, 2, 1)\": 8, \"('C', False, 0, 3, 1)\": 9, \"('C', False, 0, 4, 0)\": 10, \"('C', True, 'max', 2, 1)\": 11, \"('C', True, 'max', 3, 0)\": 12, \"('C', False, 'max', 2, 2)\": 13, \"('O', False, 0, 1, 1)\": 14, \"('C', False, 0, 1, 1)\": 15, \"('C', False, 0, 2, 0)\": 16, \"('C', False, 'max', 3, 1)\": 17, \"('N', False, 0, 1, 0)\": 18, \"('Br', False, 0, 1, 0)\": 19, \"('C', False, 'max', 2, 1)\": 20, \"('C', True, 5, 3, 0)\": 21, \"('C', False, 5, 2, 2)\": 22, \"('C', False, 5, 2, 1)\": 23, \"('C', False, 5, 3, 1)\": 24, \"('C', False, 5, 3, 0)\": 25, \"('C', False, 'max', 3, 0)\": 26, \"('O', False, 5, 2, 0)\": 27, \"('O', False, 'max', 2, 0)\": 28, \"('F', False, 0, 1, 0)\": 29, \"('C', True, 5, 2, 1)\": 30, \"('C', False, 'max', 4, 0)\": 31, \"('Cl', False, 0, 1, 0)\": 32, \"('C', False, 3, 3, 1)\": 33, \"('C', False, 3, 2, 2)\": 34, \"('O', False, 3, 2, 0)\": 35}\n"
     ]
    }
   ],
   "source": [
    "# Initially, the preprocessor has no data on atom types, so we have to loop over the \n",
    "# training set once to pre-allocate these mappings\n",
    "print(\"before pre-allocating\")\n",
    "print(preprocessor.atom_tokenizer._data)\n",
    "\n",
    "for smiles in train:\n",
    "    preprocessor(smiles, train=True)\n",
    "    \n",
    "print()\n",
    "print(\"after pre-allocating\")\n",
    "print(preprocessor.atom_tokenizer._data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3, 14], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main input types for a SMILES-based prediction\n",
    "smiles = 'CCO'\n",
    "\n",
    "# Atom types, as integer classes\n",
    "preprocessor(smiles, train=True)['atom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 5, 6], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bond types, as integer classes\n",
    "preprocessor(smiles, train=True)['bond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 2],\n",
       "       [2, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A connectivity array, where row i indicates bond i connects atom j to atom k\n",
    "preprocessor(smiles, train=True)['connectivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the tf.data pipeline. There's a lot of specifying data types and\n",
    "# expected shapes for tensorflow to pre-allocate the necessary arrays. But \n",
    "# essentially, this is responsible for calling the input constructor, batching \n",
    "# together multiple molecules, and padding the resulting molecules so that all\n",
    "# molecules in the same batch have the same number of atoms (we pad with zeros,\n",
    "# hence why the atom and bond types above start with 1 as the unknown class)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ((preprocessor(row.SMILES, train=False), row.YSI)\n",
    "             for i, row in ysi[ysi.SMILES.isin(train)].iterrows()),\n",
    "    output_signature=(preprocessor.output_signature, tf.TensorSpec((), dtype=tf.float32)))\\\n",
    "    .cache().shuffle(buffer_size=200)\\\n",
    "    .padded_batch(batch_size=64)\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ((preprocessor(row.SMILES, train=False), row.YSI)\n",
    "             for i, row in ysi[ysi.SMILES.isin(valid)].iterrows()),\n",
    "    output_signature=(preprocessor.output_signature, tf.TensorSpec((), dtype=tf.float32)))\\\n",
    "    .cache()\\\n",
    "    .padded_batch(batch_size=64)\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3, 12, ...,  0,  0,  0],\n",
       "       [ 7,  8,  3, ...,  0,  0,  0],\n",
       "       [ 7,  4,  2, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 7,  8, 12, ...,  0,  0,  0],\n",
       "       [ 2,  3,  9, ...,  0,  0,  0],\n",
       "       [ 2,  8,  8, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, outputs = next(train_dataset.as_numpy_iterator())\n",
    "inputs['atom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pstjohn/mambaforge/envs/rlmol/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    }
   ],
   "source": [
    "## Define the keras model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Input layers\n",
    "atom = layers.Input(shape=[None], dtype=tf.int64, name='atom')\n",
    "bond = layers.Input(shape=[None], dtype=tf.int64, name='bond')\n",
    "connectivity = layers.Input(shape=[None, 2], dtype=tf.int64, name='connectivity')\n",
    "\n",
    "num_features = 8  # Controls the size of the model\n",
    "\n",
    "# Convert from a single integer defining the atom state to a vector\n",
    "# of weights associated with that class\n",
    "atom_state = layers.Embedding(preprocessor.atom_classes, num_features,\n",
    "                              name='atom_embedding', mask_zero=True)(atom)\n",
    "\n",
    "# Ditto with the bond state\n",
    "bond_state = layers.Embedding(preprocessor.bond_classes, num_features,\n",
    "                              name='bond_embedding', mask_zero=True)(bond)\n",
    "\n",
    "# Here we use our first nfp layer. This is an attention layer that looks at\n",
    "# the atom and bond states and reduces them to a single, graph-level vector. \n",
    "# mum_heads * units has to be the same dimension as the atom / bond dimension\n",
    "global_state = nfp.GlobalUpdate(units=8, num_heads=1)([atom_state, bond_state, connectivity])\n",
    "\n",
    "for _ in range(3):  # Do the message passing\n",
    "    new_bond_state = nfp.EdgeUpdate()([atom_state, bond_state, connectivity, global_state])\n",
    "    bond_state = layers.Add()([bond_state, new_bond_state])\n",
    "    \n",
    "    new_atom_state = nfp.NodeUpdate()([atom_state, bond_state, connectivity, global_state])\n",
    "    atom_state = layers.Add()([atom_state, new_atom_state])\n",
    "    \n",
    "    new_global_state = nfp.GlobalUpdate(units=8, num_heads=1)(\n",
    "        [atom_state, bond_state, connectivity, global_state]) \n",
    "    global_state = layers.Add()([global_state, new_global_state])\n",
    "\n",
    "    \n",
    "# Since the final prediction is a single, molecule-level property (YSI), we \n",
    "# reduce the last global state to a single prediction.\n",
    "ysi_prediction = layers.Dense(1)(global_state)\n",
    "\n",
    "# Construct the tf.keras model\n",
    "model = tf.keras.Model([atom, bond, connectivity], [ysi_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6/6 [==============================] - 5s 245ms/step - loss: 192.0872 - val_loss: 155.4040\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 190.3157 - val_loss: 152.5118\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 186.1115 - val_loss: 145.6914\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 176.7000 - val_loss: 131.8439\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 163.8713 - val_loss: 122.8008\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 157.7288 - val_loss: 122.6877\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 153.1267 - val_loss: 117.7342\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 144.7063 - val_loss: 109.9825\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 133.6063 - val_loss: 101.3907\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 110.1535 - val_loss: 84.3457\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 77.5999 - val_loss: 61.5951\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 58.9964 - val_loss: 52.2004\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 56.7010 - val_loss: 54.1540\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 54.9731 - val_loss: 49.3258\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 49.4758 - val_loss: 49.8511\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 49.3332 - val_loss: 48.4715\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 46.6994 - val_loss: 43.7063\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 48.1494 - val_loss: 47.9336\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 50.2123 - val_loss: 46.2343\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 46.8542 - val_loss: 41.4796\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 46.0189 - val_loss: 52.0516\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 47.6934 - val_loss: 40.5394\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 48.3689 - val_loss: 47.6283\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 45.0009 - val_loss: 41.7982\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 43.0285 - val_loss: 44.1419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd206450c10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mae', optimizer=tf.keras.optimizers.Adam(1E-3))\n",
    "\n",
    "# Fit the model. The first epoch is slower, since it needs to cache\n",
    "# the preprocessed molecule inputs\n",
    "model.fit(train_dataset, validation_data=valid_dataset, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we create a test dataset that doesn't assume we know the values for the YSI\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: (preprocessor(smiles, train=False)\n",
    "             for smiles in test),\n",
    "    output_signature=preprocessor.output_signature)\\\n",
    "    .padded_batch(batch_size=64)\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.404793376922605"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here are the predictions on the test set\n",
    "test_predictions = model.predict(test_dataset)\n",
    "test_db_values = ysi.set_index('SMILES').reindex(test).YSI.values\n",
    "\n",
    "np.abs(test_db_values - test_predictions.flatten()).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
